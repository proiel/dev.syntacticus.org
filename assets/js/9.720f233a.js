(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{286:function(e,t,a){"use strict";a.r(t);var n=a(14),s=Object(n.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"introduction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),t("p",[e._v("Syntacticus is an umbrella project for several treebanks that deal specifically with the older stages of Indo-European languages. You can browse these treebanks using our "),t("a",{attrs:{href:"http://syntacticus.org",target:"_blank",rel:"noopener noreferrer"}},[e._v("end-user front end"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("p",[e._v("The raw data sets are produced, curated and hosted separatedly by each constituent treebank. The software and infrastructure that is used to create the treebanks, analyse them and browse them is shared.")]),e._v(" "),t("p",[e._v("Most of the software, as well as the annotation guidelines, were developed by the PROIEL Treebank, which is now one of the constituent treebanks of Syntacticus. You'll therefore see 'PROIEL' used in many places, especially in the name of software components. Whenever you see it, feel free to substitute Syntacticus!")]),e._v(" "),t("p",[e._v("Everything related to Syntacticus is open-source and freely available. Most of our software is released under the MIT license; some older parts are GPL licensed. The linguistic data itself and our documenation are available under various CC BY-SA licenses. The details differ between individual resources so check carefully before using. Note in particular that some of our linguistic resources have limitations on commerical use. We also greatly appreciate it if you follow standard academic practice and cite relevant publications if you use any our data.")]),e._v(" "),t("p",[e._v("The "),t("em",[e._v("PROIEL treebanking framework")]),e._v(" consists of an "),t("a",{attrs:{href:"http://dev.syntacticus.org/annotation-guide/",target:"_blank",rel:"noopener noreferrer"}},[e._v("annotation scheme"),t("OutboundLink")],1),e._v(", an XML-based interchange format and a set of tools for creating and manipulating treebanks.")]),e._v(" "),t("p",[e._v("The three main tools of the framework are")]),e._v(" "),t("ol",[t("li",[t("a",{attrs:{href:"https://github.com/mlj/proiel-webapp",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL Annotator"),t("OutboundLink")],1),e._v(", a web-based tool for creating and annotating PROIEL treebanks,")]),e._v(" "),t("li",[t("a",{attrs:{href:"http://proiel.johndal.com",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL Reader"),t("OutboundLink")],1),e._v(", a web-based treebank browser, and")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/proiel/proiel",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL Library"),t("OutboundLink")],1),e._v(", a Ruby-based library for manipulating PROIEL treebanks, whose most frequently used functionality is exposed by a "),t("a",{attrs:{href:"https://github.com/proiel/proiel-cli",target:"_blank",rel:"noopener noreferrer"}},[e._v("command-line interface"),t("OutboundLink")],1),e._v(".")])]),e._v(" "),t("p",[e._v("If you want to use an existing PROIEL treebank that you have obtained, you will only need to install the PROIEL Library.")]),e._v(" "),t("p",[e._v("If you want to create a new PROIEL treebank and set up your own infrastructure for this, you will need both PROIEL Annotator and PROIEL Reader. You should start by reading the installation instructions in the "),t("a",{attrs:{href:"https://github.com/mlj/proiel-webapp/wiki",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL Reader wiki"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("p",[e._v("The PROIEL treebanking framework is currently used by the following treebanking projects:")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"http://torottreebank.github.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Troms√∏ Old Russian and OCS Treebank (TOROT)"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("RouterLink",{attrs:{to:"/proiel/"}},[e._v("The PROIEL Treebank")])],1),e._v(" "),t("li",[t("RouterLink",{attrs:{to:"/iswoc/"}},[e._v("Information Structure and Word Order Change in Germanic and Romance Languages (ISWOC)")])],1),e._v(" "),t("li",[t("a",{attrs:{href:"http://foni.uio.no:3000",target:"_blank",rel:"noopener noreferrer"}},[e._v("Menotec"),t("OutboundLink")],1)])]),e._v(" "),t("h2",{attrs:{id:"software"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#software"}},[e._v("#")]),e._v(" Software")]),e._v(" "),t("p",[e._v("For historical reasons the components that make up Syntacticus are scattered between a number of Github projects. We're in the process of consolidating them under one organisation. Until that is done, here is a list to help you find your way:")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://github.com/proiel/proiel",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL library"),t("OutboundLink")],1),e._v(": a Ruby-based library for manipulating PROIEL treebanks ("),t("a",{attrs:{href:"http://www.rubydoc.info/gems/proiel",target:"_blank",rel:"noopener noreferrer"}},[e._v("API reference"),t("OutboundLink")],1),e._v(")")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/proiel/proiel-cli",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL CLI"),t("OutboundLink")],1),e._v(": a command-line tool for common tasks such as converting between treebank formats or extracting data for use with NLP tools. Some examples of typical usage can be found below in the section "),t("a",{attrs:{href:"#manipulating-proiel-xml-treebank-files"}},[e._v("Manipulating PROIEL XML treebank files")]),e._v(".")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/mlj/syntacticus.org",target:"_blank",rel:"noopener noreferrer"}},[e._v("syntacticus.org"),t("OutboundLink")],1),e._v(": the user-facing treebank browser on "),t("a",{attrs:{href:"http://syntacticus.org",target:"_blank",rel:"noopener noreferrer"}},[e._v("syntacticus.org"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/mlj/syntacticus-api",target:"_blank",rel:"noopener noreferrer"}},[e._v("Syntacticus API"),t("OutboundLink")],1),e._v(": the Rails API that powers "),t("a",{attrs:{href:"http://syntacticus.org",target:"_blank",rel:"noopener noreferrer"}},[e._v("syntacticus.org"),t("OutboundLink")],1),e._v(" and indexes treebanks.")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/mlj/proiel-webapp",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL Annotator"),t("OutboundLink")],1),e._v(":  a web-based tool for creating and annotating treebanks. This is a decade-old project that is in the middle of a complete rewrite; try one of the 'stable' releases which are the ones that have actually been deployed. Some (partially out-dated) documentation for this tool is available from "),t("a",{attrs:{href:"https://github.com/mlj/proiel-webapp/wiki",target:"_blank",rel:"noopener noreferrer"}},[e._v("it's wiki"),t("OutboundLink")],1),e._v(".")])]),e._v(" "),t("h2",{attrs:{id:"apis-and-libraries"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#apis-and-libraries"}},[e._v("#")]),e._v(" APIs and libraries")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("proiel")]),e._v(": "),t("a",{attrs:{href:"http://www.rubydoc.info/gems/proiel",target:"_blank",rel:"noopener noreferrer"}},[e._v("Reference documentation"),t("OutboundLink")],1),e._v(", "),t("a",{attrs:{href:"https://github.com/proiel/proiel",target:"_blank",rel:"noopener noreferrer"}},[e._v("GitHub repository"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("code",[e._v("proiel-cli")]),e._v(": "),t("a",{attrs:{href:"http://www.rubydoc.info/gems/proiel-cli",target:"_blank",rel:"noopener noreferrer"}},[e._v("Reference documentation"),t("OutboundLink")],1),e._v(", "),t("a",{attrs:{href:"https://github.com/proiel/proiel-cli",target:"_blank",rel:"noopener noreferrer"}},[e._v("GitHub repository"),t("OutboundLink")],1)])]),e._v(" "),t("h2",{attrs:{id:"manipulating-proiel-xml-treebank-files"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#manipulating-proiel-xml-treebank-files"}},[e._v("#")]),e._v(" Manipulating PROIEL XML treebank files")]),e._v(" "),t("p",[e._v("PROIEL XML files can be manipulated with our "),t("a",{attrs:{href:"https://github.com/proiel/proiel-cli",target:"_blank",rel:"noopener noreferrer"}},[e._v("command-line tools"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("p",[e._v("The easiest way to install the tools is by using Ruby's "),t("code",[e._v("gem")]),e._v(" tool:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[e._v("gem "),t("span",{pre:!0,attrs:{class:"token function"}},[e._v("install")]),e._v(" proiel-cli\n")])])]),t("p",[e._v("The general format is "),t("code",[e._v("proiel")]),e._v(" followed by a command, any options and one or more filenames:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[e._v("proiel info "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[e._v("-V")]),e._v(" caes-gal.xml cic-att.xml\n")])])]),t("p",[e._v("Most commands also require sub-commands:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[e._v("proiel convert conll "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[e._v("-V")]),e._v(" caes-gal.xml\n")])])]),t("p",[e._v("The filename arguments are the treebank files to process. All commands accept plain PROIEL XML files or gzipped PROIEL XML files:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[e._v("proiel convert conll caes-gal.xml\nproiel convert conll caes-gal.xml.gz\n")])])]),t("h3",{attrs:{id:"converting-proiel-xml-files-to-other-file-formats"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#converting-proiel-xml-files-to-other-file-formats"}},[e._v("#")]),e._v(" Converting PROIEL XML files to other file formats")]),e._v(" "),t("p",[e._v("PROIEL XML can be converted to a number of other formats using the "),t("code",[e._v("proiel")]),e._v(" utility. The following, for example, will convert a PROIEL XML file to CoNLL-X format:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("proiel convert conll-x input.xml > output.conll\n")])])]),t("p",[t("code",[e._v("proiel")]),e._v(" currently supports conversion to the following formats:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Command line")]),e._v(" "),t("th",[e._v("Target format")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("proiel convert conll-x")])]),e._v(" "),t("td",[t("a",{attrs:{href:"http://ilk.uvt.nl/conll/#dataformat",target:"_blank",rel:"noopener noreferrer"}},[e._v("CoNLL-X"),t("OutboundLink")],1),e._v(" format")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("proiel convert conll-u")])]),e._v(" "),t("td",[t("a",{attrs:{href:"http://universaldependencies.org/docs/format.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("CoNLL-U"),t("OutboundLink")],1),e._v(" format")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("proiel convert tiger")])]),e._v(" "),t("td",[t("a",{attrs:{href:"http://www.ims.uni-stuttgart.de/forschung/ressourcen/werkzeuge/TIGERSearch/doc/html/TigerXML.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("TIGER XML"),t("OutboundLink")],1),e._v(" format")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("proiel convert tiger2")])]),e._v(" "),t("td",[t("a",{attrs:{href:"http://korpling.german.hu-berlin.de/tiger2/",target:"_blank",rel:"noopener noreferrer"}},[e._v("TIGER2"),t("OutboundLink")],1),e._v(" format")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("proiel convert text")])]),e._v(" "),t("td",[e._v("plain text")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("proiel convert lexc")])]),e._v(" "),t("td",[e._v("lexc format")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("proiel convert tnt")])]),e._v(" "),t("td",[e._v("TNT/hunpos format")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("proiel convert proielxml")])]),e._v(" "),t("td",[e._v("PROIEL XML format")])])])]),e._v(" "),t("p",[e._v("Note that official releases of the PROIEL treebank already include CoNLL-X files. These can be downloaded from the "),t("RouterLink",{attrs:{to:"/proiel/"}},[e._v("PROIEL treebank")]),e._v(".")],1),e._v(" "),t("p",[e._v("Conversion to CoNLL-U is experimental and the output is likely to evolve as the Universal Dependencies project matures. Curated versions of the PROIEL treebank on CoNLL-U format can be downloaded from the "),t("a",{attrs:{href:"http://universaldependencies.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Universal Dependencies"),t("OutboundLink")],1),e._v(" project.")]),e._v(" "),t("p",[e._v("Conversion to plain text removes all information except the text itself, which is output using UTF-8 encoding with Unix line-endings ("),t("code",[e._v("LF")]),e._v(" only).")]),e._v(" "),t("p",[e._v("Conversion to PROIEL XML is intended for filtering and merging of treebanks, as well as for round-trip testing.")]),e._v(" "),t("h3",{attrs:{id:"validating-proiel-xml-files"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#validating-proiel-xml-files"}},[e._v("#")]),e._v(" Validating PROIEL XML files")]),e._v(" "),t("p",[e._v("PROIEL XML should be validated before they are distributed or before they are imported into PROIEL Annotator. The following validates two PROIEL XML files:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("proiel validate input1.xml input2.xml\n")])])]),t("p",[e._v("This will peek at the file to determine the version of PROIEL XML it uses and validate it using the appropriate XML schema. It also runs a number of integrity checks, which go beyond plain validation. In particular, "),t("code",[e._v("proiel validate")]),e._v(" verifies that cross-references between objects are valid and that the annotation is consistent with the annotation schema.")]),e._v(" "),t("p",[e._v("If any file is invalid or inconsistent, "),t("code",[e._v("proiel")]),e._v(" will print errors to "),t("code",[e._v("stderr")]),e._v(" and exit with a non-zero error code. "),t("code",[e._v("proiel")]),e._v(" validates all files before existing with an error code.")]),e._v(" "),t("p",[e._v("If you only want to validate the file using the XML schema, you can use a tool like "),t("code",[e._v("xmllint")]),e._v(". You fill find all the PROIEL XML schema files in the "),t("a",{attrs:{href:"https://github.com/proiel/proiel/tree/master/lib/proiel/proiel_xml",target:"_blank",rel:"noopener noreferrer"}},[e._v("GitHub repository"),t("OutboundLink")],1),e._v(" for the "),t("code",[e._v("proiel")]),e._v(" Ruby gem.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("xmllint --nonet --noout \\\n  --path path_to_schema_files \\\n  --schema path_to_schema_files/proiel.xsd \\\n  input.xml\n")])])]),t("h3",{attrs:{id:"merging-filtering-and-upgrading-proiel-xml-files"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#merging-filtering-and-upgrading-proiel-xml-files"}},[e._v("#")]),e._v(" Merging, filtering and upgrading PROIEL XML files")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("proiel")]),e._v(" tool can convert from PROIEL XML to PROIEL XML. This functionality is intended for (a) merging multiple PROIEL XML files into one PROIEL XML file, (b) for filtering out information from PROIEL XML files, or (c) for upgrading PROIEL XML files that use an older version of the PROIEL XML schema to the most current version.")]),e._v(" "),t("p",[e._v('{% include note-start.html title="Missing IDs" %}\n'),t("tt",[e._v("proiel convert proielxml")]),e._v(" will auto-generate any missing IDs on "),t("tt",[e._v("token")]),e._v(", "),t("tt",[e._v("sentence")]),e._v(" or "),t("tt",[e._v("div")]),e._v(" elements.\nNote in particular that PROIEL XML 2.0 and earlier did not support an "),t("tt",[e._v("id")]),e._v(" attribute on "),t("tt",[e._v("div")]),e._v(" elements. Running "),t("tt",[e._v("proiel convert proielxml")]),e._v(" on such files will produce auto-generated IDs on all "),t("tt",[e._v("div")]),e._v(" elements.\n{% include note-end.html %}")],1),e._v(" "),t("h4",{attrs:{id:"merging-files"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#merging-files"}},[e._v("#")]),e._v(" Merging files")]),e._v(" "),t("p",[e._v("Several treebank files can be merged into one treebank file by using "),t("code",[e._v("proiel convert proielxml")]),e._v(" and specifying multiple PROIEL XML files:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[e._v("proiel convert proielxml caes-gal.xml cic-att.xml\n")])])]),t("p",[e._v("The result will be a PROIEL XML file with multiple "),t("code",[e._v("source")]),e._v(" elements:")]),e._v(" "),t("div",{staticClass:"language-xml extra-class"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token prolog"}},[e._v('<?xml version="1.0" encoding="UTF-8"?>')]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("proiel")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("export-time")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("2014-12-19T12:44:28+01:00"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("schema-version")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("2.0"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("annotation")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n     ...\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("annotation")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("source")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("caes-gal"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("language")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("lat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n     ...\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("source")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("source")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("cic-att"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("language")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("lat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n     ...\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("source")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("proiel")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n")])])]),t("p",[e._v("The treebanks to be merged must all use the same schema version and the same tagset.")]),e._v(" "),t("h4",{attrs:{id:"filtering-files"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#filtering-files"}},[e._v("#")]),e._v(" Filtering files")]),e._v(" "),t("p",[e._v("Information in treebank files can be filtered using "),t("code",[e._v("proiel convert proielxml")]),e._v(". Common scenarios in which this is useful include when you need to remove one layer of annotation, remove work that is incomplete or anonymise data that includes detailed annotator information. Examples:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Remove the annotation level that includes information structure")]),e._v("\nproiel convert proielxml --remove-information-structure input.xml "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" output.xml\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Remove all sentences that have not been reviewed")]),e._v("\nproiel convert proielxml --remove-not-reviewed input.xml "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" output.xml\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Remove personal information about annotator and reviewer activity")]),e._v("\nproiel convert proielxml --remove-annotator --remove-reviewer input.xml "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" output.xml\n")])])]),t("p",[e._v("Filters can also be used for transfer of information from one source to another in certain special cases. The "),t("code",[e._v("--infer-alignments")]),e._v(" options will infer alignments between "),t("code",[e._v("div")]),e._v(" elements using alignments on tokens or sentences. For this to work, both the aligned source "),t("em",[e._v("A")]),e._v(" (which will typically be the translation of a text) and the unaligned text "),t("em",[e._v("B")]),e._v(" (which will typically be the original text that was translated) have to be loaded. However, when inferring these alignments for source "),t("em",[e._v("A")]),e._v(" it may be that you do not want to include the unaligned source "),t("em",[e._v("B")]),e._v(". In this scenario, the "),t("code",[e._v("--remove-unaligned-sources")]),e._v(" option will filter out source "),t("em",[e._v("B")]),e._v(" after the inference has taken place:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("proiel convert proielxml --infer-alignments --remove-unaligned-sources A.xml B.xml > output.xml\n")])])]),t("p",[e._v("Use "),t("code",[e._v("proiel convert proielxml --help")]),e._v(" for a full list of options.")]),e._v(" "),t("h4",{attrs:{id:"upgrading-files"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#upgrading-files"}},[e._v("#")]),e._v(" Upgrading files")]),e._v(" "),t("p",[e._v("PROIEL XML files that employ an older version of the PROIEL XML schema can be upgraded using "),t("code",[e._v("proiel convert proielxml")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[e._v("proiel convert proielxml old-schema.xml "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" new-schema.xml\n")])])]),t("p",[t("code",[e._v("proiel convert")]),e._v(" can read files that use the PROIEL XML 2.0 or higher, and "),t("code",[e._v("proiel convert proielxml")]),e._v(" will always output files that use the latest version of the PROIEL XML schema.")]),e._v(" "),t("h3",{attrs:{id:"searching-for-text"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#searching-for-text"}},[e._v("#")]),e._v(" Searching for text")]),e._v(" "),t("p",[e._v("Simple searches can be performed using "),t("code",[e._v("proiel grep")]),e._v(" followed by a regular expression. This will serahc the text (which is the "),t("code",[e._v("form")]),e._v(" attribute on tokens and any "),t("code",[e._v("presentation_before")]),e._v(" and "),t("code",[e._v("presentation_after")]),e._v(" attributes on tokens, sentences and divs) and return any text that matches the regular expression, as in this example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("$ proiel grep 'pel' caes-gal.xml\nCaes. Gal. 1.1.1 (ID = 52548) Gallia est omnis divisa in partes tres, quarum unam incolunt Belgae, aliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur.\nCaes. Gal. 1.3.3 (ID = 52570) In eo itinere persuadet Castico, Catamantaloedis filio, Sequano, cuius pater regnum in Sequanis multos annos obtinuerat et a senatu populi Romani amicus appellatus erat, ut regnum in civitate sua occuparet, quod pater ante habuerit;\n...\n$ proiel grep '^pel' caes-gal.xml\nCaes. Gal. 3.13.6 (ID = 53210) pelles pro velis alutaeque tenuiter confectae, sive propter inopiam lini atque eius usus inscientiam, sive eo, quod est magis veri simile, quod tantas tempestates Oceani tantosque impetus ventorum sustineri ac tanta onera navium regi velis non satis commode posse arbitrabantur.\n")])])]),t("p",[e._v("The regular expression is applied to one sentence at a time so the anchors "),t("code",[e._v("^")]),e._v(" and "),t("code",[e._v("$")]),e._v(" refer to the beginning and end of the sentence.")]),e._v(" "),t("p",[e._v("To apply a regular expression to each individual token instead, use the "),t("code",[e._v("--level token")]),e._v(" option:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("$ proiel grep 'pel' --level token caes-gal.xml\nCaes. Gal. 1.1.1 (ID = 680740) appellantur.\nCaes. Gal. 1.3.3 (ID = 681128) appellatus\nCaes. Gal. 1.12.4 (ID = 682300) appellabatur\n...\n$ proiel grep '^pel' --level token caes-gal.xml\nCaes. Gal. 1.31.11 (ID = 685232) pellerentur\nCaes. Gal. 2.33.2 (ID = 693103) pellibus\nCaes. Gal. 3.13.6 (ID = 852327) pelles\n...\n")])])]),t("p",[e._v("Matching is by default case sensitive. Use the "),t("code",[e._v("-i")]),e._v(" option for case-insensitive matching:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("$ proiel grep 'Gal' --level token caes-gal.xml\nCaes. Gal. 1.1.1 (ID = 680720) Gallia\nCaes. Gal. 1.1.1 (ID = 680739) Galli\nCaes. Gal. 1.1.2 (ID = 680749) Gallos\n...\n$ proiel grep 'Gal' --level token -i caes-gal.xml\n...\nCaes. Gal. 1.17.4 (ID = 761727) Gallia\nCaes. Gal. 1.18.3 (ID = 683173) vectigalia\nCaes. Gal. 1.19.3 (ID = 756644) Galliae\n...\n")])])]),t("h2",{attrs:{id:"syntactic-annotation-model"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#syntactic-annotation-model"}},[e._v("#")]),e._v(" Syntactic annotation model")]),e._v(" "),t("p",[e._v("If you are familiar with other dependency-grammar treebanks, the following is what you absolutely need to know about the PROIEL model:")]),e._v(" "),t("ol",[t("li",[t("p",[e._v("Every dependency graph has an implicit or virtual root node. This is (1) because we want to be able to label the token that would otherwise have been the root, and (2) because the annotation system allows for multiple such tokens to belong to the same graph.")])]),e._v(" "),t("li",[t("p",[e._v("Dependency graphs do not include punctuation. This is because (1) because punctuation in historical language data is highly idiosyncratic, frequently added by later editors and sometimes absent altogether, and (2) because it not part of the formal syntactic framework (Lexical-Functional Grammar) that PROIEL was inspired by.")])]),e._v(" "),t("li",[t("p",[e._v("Eeach node has only one primary dependency but may additionally have any number of secondary dependencies. These dependencies indicate various forms of coreference or coindexing.")])]),e._v(" "),t("li",[t("p",[e._v("Nodes need not correspond to overt morphemes. In specific cirumstances the model allows for nodes without any overt content. Some of these can be discarded if you dislike them (e.g. "),t("em",[e._v("pro")]),e._v("-subjects) while others are intrinsic to the model (e.g. null verbs).")])])]),e._v(" "),t("ul",[t("li",[e._v("overt root node is labelled by assuming a virtual, null root node")]),e._v(" "),t("li",[e._v("punctuation not in dep. graphs")]),e._v(" "),t("li",[e._v("secondary relations & null elements")])]),e._v(" "),t("h2",{attrs:{id:"the-proiel-xml-format"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#the-proiel-xml-format"}},[e._v("#")]),e._v(" The PROIEL XML format")]),e._v(" "),t("p",[e._v("PROIEL XML is the proprietary XML format used as the authoritative and complete long-term storage format for PROIEL treebanks. PROIEL XML is described by a schema, a set of integrity rules and additional behaviour described here.")]),e._v(" "),t("p",[e._v("As PROIEL XML as evolved, more features have been added:")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://raw.githubusercontent.com/proiel/proiel/master/lib/proiel/proiel_xml/proiel-1.0/proiel-1.0.xsd",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL XML 1.0"),t("OutboundLink")],1),e._v(" was was the first version of PROIEL XML intended for public consumption. This version is obsolete and is no longer supported by any of our tools.")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://raw.githubusercontent.com/proiel/proiel/master/lib/proiel/proiel_xml/proiel-2.0/proiel-2.0.xsd",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL XML 2.0/2.0.1"),t("OutboundLink")],1),e._v(" replaced the TEI header of version 1.0 with a sequence of pre-defined metadata elements. Although this change removed a powerful feature, it significantly simplified manipulation and validation of PROIEL XML files.")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://raw.githubusercontent.com/proiel/proiel/master/lib/proiel/proiel_xml/proiel-2.1/proiel-2.1.xsd",target:"_blank",rel:"noopener noreferrer"}},[e._v("PROIEL XML 2.1"),t("OutboundLink")],1),e._v(" ("),t("strong",[e._v("current version")]),e._v(") added several new attributes:\n"),t("ul",[t("li",[e._v("an optional "),t("code",[e._v("id")]),e._v(" attribute on "),t("code",[e._v("div")]),e._v(" elements")]),e._v(" "),t("li",[e._v("an optional "),t("code",[e._v("alignment-id")]),e._v(" attribute on "),t("code",[e._v("source")]),e._v(", "),t("code",[e._v("div")]),e._v(", "),t("code",[e._v("sentence")]),e._v(" and "),t("code",[e._v("token")]),e._v(" elements")]),e._v(" "),t("li",[e._v("optional "),t("code",[e._v("annotated-by")]),e._v(", "),t("code",[e._v("annotated-at")]),e._v(", "),t("code",[e._v("reviewed-by")]),e._v(" and "),t("code",[e._v("reviewed-at")]),e._v(" attributes on "),t("code",[e._v("sentence")]),e._v(" elements")])])]),e._v(" "),t("li",[e._v("PROIEL XML 3.0 ("),t("strong",[e._v("unreleased")]),e._v(") adds support for per-language dictionaries using the "),t("code",[e._v("dictionary")]),e._v(" element. It adds one or more optional "),t("code",[e._v("note")]),e._v(" elements under "),t("code",[e._v("source")]),e._v(", "),t("code",[e._v("div")]),e._v(", "),t("code",[e._v("sentence")]),e._v(", "),t("code",[e._v("token")]),e._v(" and "),t("code",[e._v("lemma")]),e._v(", as well as one or more optional "),t("code",[e._v("tag")]),e._v(" elements under "),t("code",[e._v("token")]),e._v(" and "),t("code",[e._v("lemma")]),e._v(". It also adds an optional "),t("code",[e._v("dialect")]),e._v(" attribute to "),t("code",[e._v("source")]),e._v(" and "),t("code",[e._v("dictionary")]),e._v(", and optional "),t("code",[e._v("alternative-title")]),e._v(", "),t("code",[e._v("chronology-composition")]),e._v(" and "),t("code",[e._v("chronology-manuscript")]),e._v(" elements below "),t("code",[e._v("source")]),e._v(".")])]),e._v(" "),t("p",[e._v("Any valid PROIEL XML 2.0 treebank is also a valid PROIEL XML 2.1 treebank, but a PROIEL XML 2.1 treebank is not a valid PROIEL XML 2.0 treebank. To ensure compatibility PROIEL XML 2.0 treebanks should be upgraded to PROIEL XML 2.1 treebanks. Any valid PROIEL XML 2.1 treebank will also be a valid PROIEL XML 3.0 treebank.")]),e._v(" "),t("p",[e._v("A single PROIEL XML file can represent an entire treebank or a subset of a treebank. In other words, a single file can contain one or more texts with incomplete or complete annotation. Within PROIEL XML a single text for annotation is called a "),t("em",[e._v("source")]),e._v(". Each source is divided into one or more "),t("em",[e._v("divs")]),e._v(". These will typically correspond to chapters or sections in a printed text. Each div contains one or more "),t("em",[e._v("sentences")]),e._v(". Each sentence finally contains one or more "),t("em",[e._v("tokens")]),e._v(". In this document, the term "),t("em",[e._v("object")]),e._v(" is used generically for sources, divs, sentences and tokens.")]),e._v(" "),t("p",[e._v("Each object has an ID which is represented as an attribute "),t("code",[e._v("id")]),e._v(" on the relevant element:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Element")]),e._v(" "),t("th",[e._v("Attribute")]),e._v(" "),t("th",[e._v("Type")]),e._v(" "),t("th",[e._v("Availability")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("source")])]),e._v(" "),t("td",[t("code",[e._v("id")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("div")])]),e._v(" "),t("td",[t("code",[e._v("id")])]),e._v(" "),t("td",[e._v("Non-negative integer, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("id")])]),e._v(" "),t("td",[e._v("Non-negative integer, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("token")])]),e._v(" "),t("td",[t("code",[e._v("id")])]),e._v(" "),t("td",[e._v("Non-negative integer, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])])])]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("id")]),e._v(" attribute on a source uniquely identifies the source within the treebank. This means that two different sources can have the same value for their "),t("code",[e._v("id")]),e._v(" attribute if they belong to different treebanks or different versions of the same treebank.")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("id")]),e._v(" attribute on divs, sentences and tokens uniquely identify the object within the source. This means that two different sentences can have the same value for their "),t("code",[e._v("id")]),e._v(" attributes if they belong to different sources.")]),e._v(" "),t("p",[e._v("While duplication of IDs is permitted in the PROIEL XML model, it is not encouraged and should be avoided if possible. Duplication may, however, be unavoidable when multiple treebanks from different vendors or multiple versions of the same treebank are combined.")]),e._v(" "),t("p",[e._v("As the table above shows, the "),t("code",[e._v("id")]),e._v(" attribute was absent from "),t("code",[e._v("div")]),e._v(" elements before PROIEL XML 2.1. This was unintentional.")]),e._v(" "),t("p",[e._v("TODO: Explain relation between ID duplication in PROIEL XML and uniqueness of XML IDs in a single XML document.")]),e._v(" "),t("p",[e._v("Objects are ordered in the sequence that they occur in the original text. The only exception (depending on how you look at it) is an empty token. An empty token is a virtual token that represents a node in the dependency graph without being present in the original text. By convention empty tokens that encode "),t("em",[e._v("pro")]),e._v("-drop are placed immediately before the head it is a dependent of, while empty verbal tokens and empty coordinating tokens are placed at the end of the sentence. While this is only a convention our supporting software assumes that this is the case when presenting formatted sentences for end-user consumption.")]),e._v(" "),t("h2",{attrs:{id:"textual-metadata"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#textual-metadata"}},[e._v("#")]),e._v(" Textual metadata")]),e._v(" "),t("p",[e._v("TODO")]),e._v(" "),t("h3",{attrs:{id:"chronological-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#chronological-data"}},[e._v("#")]),e._v(" Chronological data")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Element")]),e._v(" "),t("th",[e._v("Type")]),e._v(" "),t("th",[e._v("Availability")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("chronology-composition")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 3.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("chronology-manuscript")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 3.0")])])])]),e._v(" "),t("p",[e._v("Always use the Gregorian calendar and provide only the year, not the day, month or any other commentary.")]),e._v(" "),t("p",[e._v("Give the year as an integer and use "),t("code",[e._v("BC")]),e._v(" to denote years before year 1. Do not use other designations like "),t("code",[e._v("AD")]),e._v(" for the epoch starting with year 1:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("1040\n300 BC\n")])])]),t("p",[e._v("If the exact year is not known, but it is possible to place the event within a range of years, give the start and end of the range separated by "),t("code",[e._v("-")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("1040-1045\n30 BC-20 BC\n10 BC-10\n")])])]),t("p",[e._v("If either end-point of the range is an estimate, prefix an the estimated year by "),t("code",[e._v("c.")]),e._v(" (for "),t("em",[e._v("circa")]),e._v("):")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("c. 1050-c. 1100\nc. 10 BC-c. 10\n")])])]),t("p",[e._v("If it is not possible to give a range, give an extimated year prefixed by "),t("code",[e._v("c.")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("c. 1050\nc. 100 BC\n")])])]),t("p",[e._v("As a shorthand, a century can be given instead of a range or an estimated year:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("13th c.     (= c. 1201-c. 1300)\n1st c.      (= c. 1-c. 100)\n1st c. BC   (= c. 100 BC-c. 1 BC)\n")])])]),t("h3",{attrs:{id:"languages-and-dialects"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#languages-and-dialects"}},[e._v("#")]),e._v(" Languages and dialects")]),e._v(" "),t("p",[e._v("All sources and dictionaries require a "),t("code",[e._v("language")]),e._v(" attribute. They may also have\na "),t("code",[e._v("dialect")]),e._v(" attribute in PROIEL XML 3.0 or higher.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Element")]),e._v(" "),t("th",[e._v("Attribute")]),e._v(" "),t("th",[e._v("Type")]),e._v(" "),t("th",[e._v("Availability")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("source")])]),e._v(" "),t("td",[t("code",[e._v("language")])]),e._v(" "),t("td",[e._v("Enumeration, required")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("source")])]),e._v(" "),t("td",[t("code",[e._v("dialect")])]),e._v(" "),t("td",[e._v("Enumeration, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 3.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("dictionary")])]),e._v(" "),t("td",[t("code",[e._v("language")])]),e._v(" "),t("td",[e._v("Enumeration, required")]),e._v(" "),t("td",[e._v("PROIEL XML >= 3.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("dictionary")])]),e._v(" "),t("td",[t("code",[e._v("dialect")])]),e._v(" "),t("td",[e._v("Enumeration, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 3.0")])])])]),e._v(" "),t("p",[e._v("Language attributes contain an "),t("a",{attrs:{href:"https://iso639-3.sil.org/about",target:"_blank",rel:"noopener noreferrer"}},[e._v("ISO-639-3"),t("OutboundLink")],1),e._v(" language tag. All tags defined in the most recent version of the ISO-639-3 standard are valid. See SIL's "),t("a",{attrs:{href:"https://iso639-3.sil.org/code_tables/639/data",target:"_blank",rel:"noopener noreferrer"}},[e._v("ISO-639-3 code table"),t("OutboundLink")],1),e._v(" for a list.")]),e._v(" "),t("p",[e._v("Dialect attributes contain a dialect tag based on those proposed as "),t("a",{attrs:{href:"http://linguistlist.org/forms/langs/find-a-language-or-family.cfm#other-code",target:"_blank",rel:"noopener noreferrer"}},[e._v("LinguistList's extensions"),t("OutboundLink")],1),e._v(". These can be browsed using "),t("a",{attrs:{href:"http://new.multitree.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MultiTree"),t("OutboundLink")],1),e._v(" and there is a list of language tags for "),t("a",{attrs:{href:"http://multitree.org/codes/extinct.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("extinct languages"),t("OutboundLink")],1),e._v(". Unfortunately, some of these involve ISO-639-3 tags that have been proposed, but never accepted (e.g. "),t("code",[e._v("vsn")]),e._v(" for "),t("a",{attrs:{href:"https://iso639-3.sil.org/request/2011-041",target:"_blank",rel:"noopener noreferrer"}},[e._v("Vedic Sanskrit"),t("OutboundLink")],1),e._v("). PROIEL XML instead using dialect tags and an existing ISO-639-9 tag whenever possible.")]),e._v(" "),t("p",[e._v("The following is a list of language and dialect tags for which complete or partial support already exists within the toolchain:")]),e._v(" "),t("ul",[t("li",[e._v("Language tag "),t("code",[e._v("ang")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/ang.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old English"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("chu")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/chu.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Church Slavonic"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("fro")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/fro.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old French"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("got")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/got.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Gothic"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("grc")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/grc.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ancient Greek"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("hit")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/hit.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Hittite"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("lat")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/lat.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Latin"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("lit")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/lit.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Lithuanian"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("non")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/non.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Norse"),t("OutboundLink")],1),e._v(" "),t("ul",[t("li",[e._v("Dialect tag "),t("code",[e._v("dan")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/non-dan.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Danish"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Dialect tag "),t("code",[e._v("ice")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/non-ice.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Icelandic"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Dialect tag "),t("code",[e._v("ono")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/non-ono.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Norwegian"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Dialect tag "),t("code",[e._v("swe")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/non-swe.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Swedish"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("orv")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/orv.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Russian"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("osp")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/osp.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Old Spanish"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("por")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/por.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Portuguese"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("san")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/san.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sanskrit"),t("OutboundLink")],1),e._v(" "),t("ul",[t("li",[e._v("Dialect tag "),t("code",[e._v("vsn")]),e._v(": Vedic Sanskrit")])])]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("spa")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/spa.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Spanish"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Language tag "),t("code",[e._v("xcl")]),e._v(": "),t("a",{attrs:{href:"http://multitree.org/codes/xcl.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Classical Armenian"),t("OutboundLink")],1)])]),e._v(" "),t("p",[e._v("Note that there is no support for language or dialect attributes on specific elements within sources or dictionaries, nor is there support for distinguishing between scripts (e.g. Cyrillic or Glagolitic for Old Church Slavonic).")]),e._v(" "),t("h2",{attrs:{id:"annotation-metadata"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#annotation-metadata"}},[e._v("#")]),e._v(" Annotation metadata")]),e._v(" "),t("p",[e._v("TODO")]),e._v(" "),t("h3",{attrs:{id:"annotation-status"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#annotation-status"}},[e._v("#")]),e._v(" Annotation status")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Element")]),e._v(" "),t("th",[e._v("Attribute")]),e._v(" "),t("th",[e._v("Type")]),e._v(" "),t("th",[e._v("Availability")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("status")])]),e._v(" "),t("td",[e._v("Enumeration, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("annotated_by")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("reviewed_by")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("annotated_at")])]),e._v(" "),t("td",[e._v("Time stamp, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("reviewed_at")])]),e._v(" "),t("td",[e._v("Time stamp, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])])])]),e._v(" "),t("p",[e._v("TODO: "),t("code",[e._v("status")])]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("status")]),e._v(" attribute must be one of "),t("code",[e._v("unannotated")]),e._v(", "),t("code",[e._v("annotated")]),e._v(" and "),t("code",[e._v("reviewed")]),e._v(". If absent, it should be understood as having the value "),t("code",[e._v("unannotated")]),e._v(".")]),e._v(" "),t("p",[e._v("TODO: "),t("code",[e._v("annotated_by")]),e._v(", "),t("code",[e._v("reviewed_by")]),e._v("\nTODO: "),t("code",[e._v("annotated_at")]),e._v(", "),t("code",[e._v("reviewed_at")])]),e._v(" "),t("h2",{attrs:{id:"lemma-part-of-speech-and-morphology"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lemma-part-of-speech-and-morphology"}},[e._v("#")]),e._v(" Lemma, part of speech and morphology")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Element")]),e._v(" "),t("th",[e._v("Attribute")]),e._v(" "),t("th",[e._v("Type")]),e._v(" "),t("th",[e._v("Availability")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("token")])]),e._v(" "),t("td",[t("code",[e._v("lemma")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("token")])]),e._v(" "),t("td",[t("code",[e._v("part-of-speech")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("token")])]),e._v(" "),t("td",[t("code",[e._v("morphology")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])])])]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("lemma")]),e._v(" attribute contains the lemma associated with the token, i.e. the dictionary form of the token.")]),e._v(" "),t("p",[e._v("When it is necessary to distinguish between multiple lemmas with the same textual form, the PROIEL XML convention is use the associated part of speech to distinguish them.")]),e._v(" "),t("p",[e._v("If there are multiple lemmas with the same textual form and the same part of speech, the convention is to append "),t("code",[e._v("#")]),e._v(" and a positive, non-zero integer:")]),e._v(" "),t("div",{staticClass:"language-xml extra-class"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("token")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("lemma")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("quod#1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("part-of-speech")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("Df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("..."),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("token")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("token")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("lemma")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("quod#2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("part-of-speech")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("Df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("..."),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("token")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n")])])]),t("p",[e._v("Lemma uniqueness is therefore determined by the pair ("),t("code",[e._v("lemma")]),e._v(", "),t("code",[e._v("part-of-speech")]),e._v(").")]),e._v(" "),t("p",[e._v("It is a good idea to number lemmas consecutively but nothing in the model assumes that this is the case.")]),e._v(" "),t("h3",{attrs:{id:"part-of-speech-tags"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#part-of-speech-tags"}},[e._v("#")]),e._v(" Part of speech tags")]),e._v(" "),t("p",[e._v("Parts of speech are defined in the annotation schema included in a PROIEL XML file. For ease of reference, the table below gives the default parts of speech for a PROIEL XML 2.1 treebank:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Tag")]),e._v(" "),t("th",[e._v("Part of speech")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("A-")])]),e._v(" "),t("td",[e._v("adjective")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("C-")])]),e._v(" "),t("td",[e._v("conjunction")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Df")])]),e._v(" "),t("td",[e._v("adverb")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Dq")])]),e._v(" "),t("td",[e._v("relative adverb")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Du")])]),e._v(" "),t("td",[e._v("interrogative adverb")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("F-")])]),e._v(" "),t("td",[e._v("foreign word")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("G-")])]),e._v(" "),t("td",[e._v("subjunction")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("I-")])]),e._v(" "),t("td",[e._v("interjection")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Ma")])]),e._v(" "),t("td",[e._v("cardinal numeral")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Mo")])]),e._v(" "),t("td",[e._v("ordinal numeral")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("N-")])]),e._v(" "),t("td",[e._v("infinitive marker")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Nb")])]),e._v(" "),t("td",[e._v("common noun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Ne")])]),e._v(" "),t("td",[e._v("proper noun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Pc")])]),e._v(" "),t("td",[e._v("reciprocal pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Pd")])]),e._v(" "),t("td",[e._v("demonstrative pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Pi")])]),e._v(" "),t("td",[e._v("interrogative pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Pk")])]),e._v(" "),t("td",[e._v("personal reflexive pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Pp")])]),e._v(" "),t("td",[e._v("personal pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Pr")])]),e._v(" "),t("td",[e._v("relative pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Ps")])]),e._v(" "),t("td",[e._v("possessive pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Pt")])]),e._v(" "),t("td",[e._v("possessive reflexive pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Px")])]),e._v(" "),t("td",[e._v("indefinite pronoun")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("Py")])]),e._v(" "),t("td",[e._v("quantifier")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("R-")])]),e._v(" "),t("td",[e._v("preposition")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("S-")])]),e._v(" "),t("td",[e._v("article")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("V-")])]),e._v(" "),t("td",[e._v("verb")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("X-")])]),e._v(" "),t("td",[e._v("unassigned")])])])]),e._v(" "),t("h3",{attrs:{id:"morphology-tags"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#morphology-tags"}},[e._v("#")]),e._v(" Morphology tags")]),e._v(" "),t("p",[e._v("The morphology tags consist of 11 fields encoding different features. The following table shows the globally valid values for each field in order. There are also language-specific restrictions on valid morphology tags.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Field")]),e._v(" "),t("th",[e._v("Possible value")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("person")]),e._v(" "),t("td",[t("code",[e._v("1")]),e._v(", "),t("code",[e._v("2")]),e._v(", "),t("code",[e._v("3")])])]),e._v(" "),t("tr",[t("td",[e._v("number")]),e._v(" "),t("td",[t("code",[e._v("d")]),e._v(" (dual), "),t("code",[e._v("e")]),e._v("(s. or p.), "),t("code",[e._v("p")]),e._v(" (plural),  "),t("code",[e._v("s")]),e._v(" (singular), "),t("code",[e._v("x")]),e._v(" (uncertain)")])]),e._v(" "),t("tr",[t("td",[e._v("tense")]),e._v(" "),t("td",[t("code",[e._v("a")]),e._v(" (aorist), "),t("code",[e._v("f")]),e._v(" (future), "),t("code",[e._v("i")]),e._v(" (imperfect), "),t("code",[e._v("l")]),e._v(" (pluperfect), "),t("code",[e._v("p")]),e._v(" (present),  "),t("code",[e._v("r")]),e._v(" (perfect), "),t("code",[e._v("s")]),e._v(" (resultative),  "),t("code",[e._v("t")]),e._v(" (future perfect), "),t("code",[e._v("u")]),e._v(" (past), "),t("code",[e._v("x")]),e._v(" (uncertain)")])]),e._v(" "),t("tr",[t("td",[e._v("mood")]),e._v(" "),t("td",[t("code",[e._v("d")]),e._v(" (gerund),  "),t("code",[e._v("g")]),e._v(" (gerundive), "),t("code",[e._v("i")]),e._v(" (indicative), "),t("code",[e._v("m")]),e._v(" (imperative), "),t("code",[e._v("n")]),e._v(" (infintive), "),t("code",[e._v("o")]),e._v(" (optative),  "),t("code",[e._v("p")]),e._v(" (participle), "),t("code",[e._v("s")]),e._v(" (subjunctive),  "),t("code",[e._v("u")]),e._v(" (supine), "),t("code",[e._v("x")]),e._v(" (uncertain)")])]),e._v(" "),t("tr",[t("td",[e._v("voice")]),e._v(" "),t("td",[t("code",[e._v("a")]),e._v(" (active),  "),t("code",[e._v("e")]),e._v(" (middle or passive), "),t("code",[e._v("m")]),e._v(" (middle), "),t("code",[e._v("p")]),e._v(" (passive), "),t("code",[e._v("x")]),e._v(" (uncertain)")])]),e._v(" "),t("tr",[t("td",[e._v("gender")]),e._v(" "),t("td",[t("code",[e._v("f")]),e._v(" (feminine), "),t("code",[e._v("m")]),e._v(" (masculine), "),t("code",[e._v("n")]),e._v(" (neuter), "),t("code",[e._v("o")]),e._v(" (m. or n.), "),t("code",[e._v("p")]),e._v(" (m. or f.), "),t("code",[e._v("q")]),e._v(" (m., f. or n.), "),t("code",[e._v("r")]),e._v(" (f. or n.), "),t("code",[e._v("x")]),e._v(" (uncertain)")])]),e._v(" "),t("tr",[t("td",[e._v("case")]),e._v(" "),t("td",[t("code",[e._v("a")]),e._v(" (accusative), "),t("code",[e._v("b")]),e._v(" (ablative), "),t("code",[e._v("c")]),e._v(" (genitive or dative), "),t("code",[e._v("d")]),e._v(" (dative), "),t("code",[e._v("e")]),e._v(" (acc. or dat.), "),t("code",[e._v("g")]),e._v(" (genitive), "),t("code",[e._v("i")]),e._v(" (instrumental),  "),t("code",[e._v("k")]),e._v(" (nom. or acc.), "),t("code",[e._v("l")]),e._v(" (locative), "),t("code",[e._v("n")]),e._v(" (nominative), "),t("code",[e._v("o")]),e._v(" (oblique),  "),t("code",[e._v("v")]),e._v(" (vocative), "),t("code",[e._v("x")]),e._v(" (uncertain), "),t("code",[e._v("z")]),e._v(" (no case)")])]),e._v(" "),t("tr",[t("td",[e._v("degree")]),e._v(" "),t("td",[t("code",[e._v("c")]),e._v(" (comparative), "),t("code",[e._v("p")]),e._v(" (positive), "),t("code",[e._v("s")]),e._v(" (superlative), "),t("code",[e._v("x")]),e._v(" (uncertain), "),t("code",[e._v("z")]),e._v(" (no degree)")])]),e._v(" "),t("tr",[t("td",[e._v("strength")]),e._v(" "),t("td",[t("code",[e._v("s")]),e._v(" (strong), "),t("code",[e._v("t")]),e._v(" (weak or strong), "),t("code",[e._v("w")]),e._v(" (weak)")])]),e._v(" "),t("tr",[t("td",[e._v("inflection")]),e._v(" "),t("td",[t("code",[e._v("i")]),e._v(" (inflecting), "),t("code",[e._v("n")]),e._v(" (non-inflecting)")])])])]),e._v(" "),t("h2",{attrs:{id:"dependency-relations"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dependency-relations"}},[e._v("#")]),e._v(" Dependency relations")]),e._v(" "),t("p",[e._v("TODO")]),e._v(" "),t("p",[e._v("Dependency relations are defined in the annotation schema included in a PROIEL XML file. For ease of reference, the table below gives the default dependency relations for a PROIEL XML 2.1 treebank:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Tag")]),e._v(" "),t("th",[e._v("Dependency relation")]),e._v(" "),t("th",[e._v("Primary relation")]),e._v(" "),t("th",[e._v("Secondary relation")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("adnom")])]),e._v(" "),t("td",[e._v("adnominal")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("adv")])]),e._v(" "),t("td",[e._v("adverbial")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("ag")])]),e._v(" "),t("td",[e._v("agens")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("apos")])]),e._v(" "),t("td",[e._v("apposition")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("arg")])]),e._v(" "),t("td",[e._v("argument (object or oblique)")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("atr")])]),e._v(" "),t("td",[e._v("attribute")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("aux")])]),e._v(" "),t("td",[e._v("auxiliary")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("comp")])]),e._v(" "),t("td",[e._v("complement")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("expl")])]),e._v(" "),t("td",[e._v("expletive")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("narg")])]),e._v(" "),t("td",[e._v("adnominal argument")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("nonsub")])]),e._v(" "),t("td",[e._v("non-subject (object, oblique or adverbial)")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("obj")])]),e._v(" "),t("td",[e._v("object")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("obl")])]),e._v(" "),t("td",[e._v("oblique")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("parpred")])]),e._v(" "),t("td",[e._v("parenthetical predication")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("part")])]),e._v(" "),t("td",[e._v("partitive")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("per")])]),e._v(" "),t("td",[e._v("peripheral (oblique or adverbial)")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("pid")])]),e._v(" "),t("td",[e._v("predicate identity")]),e._v(" "),t("td",[e._v("No")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("pred")])]),e._v(" "),t("td",[e._v("predicate")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("rel")])]),e._v(" "),t("td",[e._v("apposition or attribute")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sub")])]),e._v(" "),t("td",[e._v("subject")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("voc")])]),e._v(" "),t("td",[e._v("vocative")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("xadv")])]),e._v(" "),t("td",[e._v("open adverbial complement")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("xobj")])]),e._v(" "),t("td",[e._v("open objective complement")]),e._v(" "),t("td",[e._v("Yes")]),e._v(" "),t("td",[e._v("Yes")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("xsub")])]),e._v(" "),t("td",[e._v("external subject")]),e._v(" "),t("td",[e._v("No")]),e._v(" "),t("td",[e._v("Yes")])])])]),e._v(" "),t("h2",{attrs:{id:"information-structure"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#information-structure"}},[e._v("#")]),e._v(" Information structure")]),e._v(" "),t("p",[e._v("TODO")]),e._v(" "),t("p",[e._v("Information statuses are defined in the annotation schema included in a PROIEL XML file. For ease of reference, the table below gives the default information statuses for a PROIEL XML 2.1 treebank:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Tag")]),e._v(" "),t("th",[e._v("Information status")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("acc_gen")])]),e._v(" "),t("td",[e._v("acc-gen")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("acc_inf")])]),e._v(" "),t("td",[e._v("acc-inf")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("acc_sit")])]),e._v(" "),t("td",[e._v("acc-sit")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("info_unannotatable")])]),e._v(" "),t("td",[e._v("unannotatable")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("kind")])]),e._v(" "),t("td",[e._v("kind")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("new")])]),e._v(" "),t("td",[e._v("new")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("no_info_status")])]),e._v(" "),t("td",[e._v("annotatable (undecided)")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("non_spec_inf")])]),e._v(" "),t("td",[e._v("inferred from non-specific")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("non_spec_old")])]),e._v(" "),t("td",[e._v("non-specific old")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("non_spec")])]),e._v(" "),t("td",[e._v("non-specific")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("old_inact")])]),e._v(" "),t("td",[e._v("old-inact")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("old")])]),e._v(" "),t("td",[e._v("old")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("quant")])]),e._v(" "),t("td",[e._v("quantifier restriction")])])])]),e._v(" "),t("h2",{attrs:{id:"alignments"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#alignments"}},[e._v("#")]),e._v(" Alignments")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Element")]),e._v(" "),t("th",[e._v("Attribute")]),e._v(" "),t("th",[e._v("Type")]),e._v(" "),t("th",[e._v("Availability")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("source")])]),e._v(" "),t("td",[t("code",[e._v("alignment-id")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("div")])]),e._v(" "),t("td",[t("code",[e._v("alignment-id")])]),e._v(" "),t("td",[e._v("Non-negative integer, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("alignment-id")])]),e._v(" "),t("td",[e._v("Non-negative integer, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("token")])]),e._v(" "),t("td",[t("code",[e._v("alignment-id")])]),e._v(" "),t("td",[e._v("Non-negative integer, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 2.1")])])])]),e._v(" "),t("p",[e._v("The PROIEL model supports alignments between sources, between divs in different sources, between sentences in different sources and between tokens in different sources.")]),e._v(" "),t("p",[e._v("Alignments between objects are one-to-many; many-to-many alignments are not supported. As an illustration, this means that the model can express alignments between the Latin translation of the New Testament and the Ancient Greek original, between the Old Church Slavonic translation and the Ancient Greek original, and so on, but it cannot at the same time express alignments between the Latin and Old Church Slavonic translations.")]),e._v(" "),t("p",[e._v("Given this restriction, alignments are encoded in PROIEL XML on an abbreviated form. Objects whose alignment is defined have the attribute "),t("code",[e._v("alignment-id")]),e._v(" with the ID of the aligned object. As the IDs of divs, sentences and tokens are unique only within each source (see section "),t("a",{attrs:{href:"#object-ids"}},[e._v("Object IDs")]),e._v("), the "),t("code",[e._v("alignment-id")]),e._v(" on "),t("code",[e._v("div")]),e._v(", "),t("code",[e._v("sentence")]),e._v(" and "),t("code",[e._v("token")]),e._v(" elements must be interpreted in relation to the "),t("code",[e._v("alignment-id")]),e._v(" on the "),t("code",[e._v("source")]),e._v(" element.")]),e._v(" "),t("p",[e._v("In the example below, "),t("code",[e._v("text1")]),e._v(" is aligned to "),t("code",[e._v("text2")]),e._v(". The alignment of token "),t("code",[e._v("12345678")]),e._v(" in "),t("code",[e._v("text1")]),e._v(" should be understood to be with token "),t("code",[e._v("12345678")]),e._v(" in "),t("code",[e._v("text2")]),e._v(". Similarly, sentence "),t("code",[e._v("123")]),e._v(" is aligned with sentence "),t("code",[e._v("456")]),e._v(" in "),t("code",[e._v("text2")]),e._v(", and div "),t("code",[e._v("12")]),e._v(" with div "),t("code",[e._v("10000")]),e._v(" in "),t("code",[e._v("text2")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language-xml extra-class"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("source")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("text1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("alignment-id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("text2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n  ...\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("div")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("12"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("alignment-id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("10000"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n    ...\n    "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("sentence")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("123"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("alignment-id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("456"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n      ...\n      "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("token")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("12345678"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("alignment-id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("12345678"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("/>")])]),e._v("\n      ...\n    "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("sentence")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n    ...\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("div")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n  ...\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("source")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n")])])]),t("p",[e._v("This means that if the source element lacks an "),t("code",[e._v("alignment-id")]),e._v(" attribute, but one of its descendant "),t("code",[e._v("div")]),e._v(", "),t("code",[e._v("sentence")]),e._v(" or "),t("code",[e._v("token")]),e._v(" elements has an "),t("code",[e._v("alignment-id")]),e._v(" attribute, the PROIEL XML file is inconsistent. This constraint can be verified using "),t("code",[e._v("proiel validate")]),e._v(".")]),e._v(" "),t("p",[e._v("If an object is aligned to multiple objects in the aligned source, the IDs are separated by a comma:")]),e._v(" "),t("div",{staticClass:"language-xml extra-class"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("source")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("text1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("alignment-id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("text2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n  ...\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("div")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("12"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("alignment-id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("10000"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n    ...\n    "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("sentence")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("123"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("alignment-id")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("456,457"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n      ...\n    "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("sentence")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n    ...\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("div")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n  ...\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("</")]),e._v("source")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n")])])]),t("p",[e._v("Object alignments should be internally consistent. If, for example, token "),t("em",[e._v("x")]),e._v(" belonging to sentence "),t("em",[e._v("a")]),e._v(" is aligned with token "),t("em",[e._v("y")]),e._v(" belonging to sentence "),t("em",[e._v("b")]),e._v(", sentence "),t("em",[e._v("a")]),e._v(" must be aligned to sentence "),t("em",[e._v("b")]),e._v(". Note that a PROIEL XML file does not have to provide alignments on all objects, e.g. if token "),t("em",[e._v("x")]),e._v(" is aligned to token "),t("em",[e._v("y")]),e._v(" the PROIEL XML file does not have to specify that sentence "),t("em",[e._v("a")]),e._v(" is aligned to sentence "),t("em",[e._v("b")]),e._v(", but if an alignment for sentence "),t("em",[e._v("a")]),e._v(" is specified it has to specify alignment with sentence "),t("em",[e._v("b")]),e._v(". This constraint can be verified using "),t("code",[e._v("proiel validate")]),e._v(".")]),e._v(" "),t("h2",{attrs:{id:"references-to-external-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#references-to-external-data"}},[e._v("#")]),e._v(" References to external data")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Element")]),e._v(" "),t("th",[e._v("Attribute")]),e._v(" "),t("th",[e._v("Type")]),e._v(" "),t("th",[e._v("Availability")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("sentence")])]),e._v(" "),t("td",[t("code",[e._v("foreign-ids")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("token")])]),e._v(" "),t("td",[t("code",[e._v("foreign-ids")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("lemma")])]),e._v(" "),t("td",[t("code",[e._v("foreign-ids")])]),e._v(" "),t("td",[e._v("String, optional")]),e._v(" "),t("td",[e._v("PROIEL XML >= 1.0")])])])]),e._v(" "),t("p",[e._v("The attribute "),t("code",[e._v("foreign_ids")]),e._v(" is intended for storing user-defined references to external data of any kind. No particular format is required but the convention is to use a comma-separated list of key=value pairs, such as")]),e._v(" "),t("div",{staticClass:"language-xml extra-class"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("<")]),e._v("token")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("...")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[e._v("foreign_ids")]),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[e._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')]),e._v("source_segment_id=T567,witness=CA"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")])]),e._v("\n")])])]),t("h2",{attrs:{id:"representation-of-textual-values"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#representation-of-textual-values"}},[e._v("#")]),e._v(" Representation of textual values")]),e._v(" "),t("p",[e._v("All text should be encoded using UTF-8. It is also recommended that all text is on "),t("a",{attrs:{href:"http://www.unicode.org/reports/tr15/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Unicode Normalization form C"),t("OutboundLink")],1),e._v(". (As PROIEL XML uses XML, it is technically possible to use a different encoding if you specify this in the XML prologue but there is really no good reason to do this, so don't!)")]),e._v(" "),t("p",[e._v("Whitespace in textual values is by default not considered significant. If a text value contains whitespace that should be significant, as in, for example, poetry and drama, the following Unicode characters should be used:")]),e._v(" "),t("ul",[t("li",[e._v("For a line break, use "),t("a",{attrs:{href:"https://codepoints.net/U+2028",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("U+2028 (LINE SEPARATOR)")]),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("For a paragraph break, use "),t("a",{attrs:{href:"https://codepoints.net/U+2029",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("U+2029 (PARAGRAPH SEPARATOR)")]),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("For an indented line (in poetry, after a line break), use TODO")]),e._v(" "),t("li",[e._v("For a caesura (in poetry, within a line), use TODO")])]),e._v(" "),t("p",[e._v("We see here that PROIEL XML ascribes additional presentational properties to some Unicode code points. PROIEL XML sets aside a number of Unicode code points for this. Most belong to one of the Private Use Areas except for two code points whose Unicode definition already provide a good fit for PROIEL XML's use of them. The following code points are given a special interpretation:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Code point and character name")]),e._v(" "),t("th",[e._v("Function in PROIEL XML")]),e._v(" "),t("th",[e._v("HTML rendering")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("U+2028 LINE SEPARATOR")])]),e._v(" "),t("td",[e._v("End of line in poetry/drama")]),e._v(" "),t("td",[t("code",[e._v("<br>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+2029 PARAGRAPH SEPARATOR")])]),e._v(" "),t("td",[e._v("End of paragraph in poetry/drama")]),e._v(" "),t("td",[t("code",[e._v("<p>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F000 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("Start of italics")]),e._v(" "),t("td",[t("code",[e._v("<i>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F001 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("Start of subscript")]),e._v(" "),t("td",[t("code",[e._v("<sub>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F002 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("Start of superscript")]),e._v(" "),t("td",[t("code",[e._v("<sup>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F003 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("Start of bold face")]),e._v(" "),t("td",[t("code",[e._v("<b>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F100 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("End of italics")]),e._v(" "),t("td",[t("code",[e._v("</i>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F101 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("End of subscript")]),e._v(" "),t("td",[t("code",[e._v("</sub>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F102 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("End of superscript")]),e._v(" "),t("td",[t("code",[e._v("</sup>")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("U+F103 PRIVATE USE CODEPOINT")])]),e._v(" "),t("td",[e._v("End of bold face")]),e._v(" "),t("td",[t("code",[e._v("</b>")])])])])]),e._v(" "),t("p",[e._v("Taking into account the rules for representation of whitespace and code points with special intepretation, the procedure for rendering a textual value as HTML is as follows:")]),e._v(" "),t("ol",[t("li",[e._v("Concatenate all textual values columns in their implicit order, including any relevant metadata like citations if required.")]),e._v(" "),t("li",[e._v("Map each code point in the table above to their recommended HTML translation.")]),e._v(" "),t("li",[e._v("Replace any sequence of whitespace with a single "),t("code",[e._v("U+0020 (SPACE)")]),e._v(" character.")]),e._v(" "),t("li",[e._v("Remove any whitespace from the beginning and end of the string.")])]),e._v(" "),t("h2",{attrs:{id:"managing-proiel-annotator"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#managing-proiel-annotator"}},[e._v("#")]),e._v(" Managing PROIEL Annotator")]),e._v(" "),t("h3",{attrs:{id:"importing-texts"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#importing-texts"}},[e._v("#")]),e._v(" Importing texts")]),e._v(" "),t("p",[e._v("PROIEL Annotator only supports importing text from PROIEL XML files. If you already have an electronic text on a pure-text format, an easy way to get started is to use the "),t("code",[e._v("proiel")]),e._v(" tool as a scaffolding tool. The only requirement is that the file uses UTF-8 encoding. If this is the case, you can use the the "),t("code",[e._v("proiel tokenize")]),e._v(" command to produce a PROIEL XML file that can be imported without further modification:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("proiel tokenize raw_text.txt > new_text.xml\n")])])]),t("p",[t("code",[e._v("proiel tokenize")]),e._v(" uses generic tokenisation rules to split paragraphs into sentences and sentences into tokens. It tokenises the text by assuming that any whitespace or punctuation is a token divider, and that periods, colons, semicolons, exclamation marks and question marks (but not commas) are sentence dividers. This is likely to produce unexpected results in some situations, and quite frequently situations if the orthography of the language is very different from that of Latin-like languages. In such cases you should consider writing your own preprocessing script as bad tokenisation will slow down annotation significantly.")]),e._v(" "),t("p",[t("code",[e._v("proiel tokenize")]),e._v(" interprets some symbols as the start of headings and some symbols as delimiting references. The use of these symbols is modelled on Markdown with preambles:")]),e._v(" "),t("ul",[t("li",[e._v("A blank line represents a paragraph break.")]),e._v(" "),t("li",[e._v("A hash symbol ("),t("code",[e._v("#")]),e._v(") at the start of a line is interpreted as the start of a new "),t("code",[e._v("div")]),e._v(". Any text after the hash symbol is used as the heading of the "),t("code",[e._v("div")]),e._v(".")]),e._v(" "),t("li",[e._v("A percentage symbol ("),t("code",[e._v("%")]),e._v(") at the start of a line is interpreted as a metadata variable and value.")]),e._v(" "),t("li",[e._v("A section symbol ("),t("code",[e._v("¬ß")]),e._v(") anywhere in the text indicates a reference. The reference ends when whitespace is encountered (and this whitespace is not part of the reference).")]),e._v(" "),t("li",[e._v("An at symbol ("),t("code",[e._v("@")]),e._v(") anywhere in the text indicates text that cannot be annotated. The text ends when whitespace is encountered (and this whitespace is not part of the text that cannot be annotated).")])]),e._v(" "),t("p",[e._v("All whitespace is replaced by a single space except for line breaks (carriage return, line feed or both), which are preserved (and replaced by code point "),t("code",[e._v("U+2028")]),e._v("). This behaviour preserves the formatting of poetry and drama but produces undesirable results for prose where line breaks usually do not carry any meaning. For prose it is therefore important to remove any line breaking within paragraphs before running "),t("code",[e._v("proiel tokenize")]),e._v(". Failure to do this before applying "),t("code",[e._v("proiel tokenize")]),e._v(" will result in time-consuming corrections later during annotation.")]),e._v(" "),t("p",[e._v("Whichever method you use to prepare a PROIEL XML file, you should validate the PROIEL XML file before attempting to import it. This will allow you to correct any syntax errors or inconsistencies before starting the import process. Once the PROIEL XML file passes the validation step, it can be imported. Make sure that you specify the correct environment when importing a text. If you do not specify the environment, the text will be imported into the development environment.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("# Validate file\nproiel validate new_text.xml\n\n# Import text\nRAILS_ENV=production proiel-webapp import text new_text.xml\n")])])]),t("p",[e._v("Note that if the import process fails, any changes made to the PROIEL Annotator database by the import process will be automatically reverted.")]),e._v(" "),t("p",[e._v("TODO: this has not been reimplemented in master: "),t("code",[e._v("id_map_filename = nil #FIXME")])]),e._v(" "),t("p",[e._v("If your PROIEL XML file already contains ID attributes for sentences, tokens or other objects, these will "),t("em",[e._v("not")]),e._v(" be preserved. Due to limitations of the underlying database, PROIEL Annotator has to generate new IDs for these objects. If it is important to keep a record of old and new IDs, you should use the  "),t("code",[e._v("ID_MAP_FILE")]),e._v(" on import:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("bundle exec rake proiel:text:import FILE=new_text.xml ID_MAP_FILE=new_text.csv\n")])])]),t("p",[e._v("The resulting mapping file is a comma-separated file with the object type in the first column, the ID in the XML file in the second column and the new, generated ID in the database in the third column:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("token,268872,2582728\ntoken,268873,2582729\ntoken,268874,2582730\ntoken,268875,2582731\ntoken,862448,2582732\nsentence,14783,218784\n")])])]),t("h3",{attrs:{id:"exporting-texts"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#exporting-texts"}},[e._v("#")]),e._v(" Exporting texts")]),e._v(" "),t("p",[e._v("Texts can be exported from PROIEL Annotator using the "),t("code",[e._v("proiel-webapp")]),e._v(" command-line tool. The only supported format is the PROIEL XML, but you can use the "),t("code",[e._v("proiel")]),e._v(" command-line tool to convert PROIEL XML to a number of other formats.")]),e._v(" "),t("p",[e._v("To export a specific text, add the numeric ID of the text (that is the ID found in the "),t("code",[e._v("id")]),e._v(" column in the "),t("code",[e._v("sources")]),e._v(" table) and a filename:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("proiel-webapp export text 1 greek-nt.xml\n")])])]),t("p",[e._v("If you omit the filename, "),t("code",[e._v("proiel-webapp")]),e._v(" will infer a filename from the "),t("code",[e._v("code")]),e._v(" column in the "),t("code",[e._v("sources")]),e._v(" table. For example, if the source with ID 2 has "),t("code",[e._v("code")]),e._v(" set to "),t("code",[e._v("marianus")]),e._v(", "),t("code",[e._v("proiel-webapp")]),e._v(" will use the filename "),t("code",[e._v("marianus.xml")]),e._v(". If you omit the ID as well, "),t("code",[e._v("proiel-webapp")]),e._v(" will export all texts in the database and infer filenames them.")]),e._v(" "),t("p",[e._v("All texts are exported to the current working directory.")]),e._v(" "),t("p",[e._v("Note that texts are not automatically validated as part of the export process. You should therefore manually validate each exported text using the "),t("code",[e._v("proiel")]),e._v(" command-line tool:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("proiel validate greek-nt.xml\n")])])]),t("p",[e._v("Make sure that you specify the correct environment when exporting texts:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("RAILS_ENV=production proiel-webapp export text 1 greek-nt.xml\n")])])]),t("p",[e._v("If you do not specify an environment, the text will be exported from the development environment.")]),e._v(" "),t("h3",{attrs:{id:"deleting-texts"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#deleting-texts"}},[e._v("#")]),e._v(" Deleting texts")]),e._v(" "),t("p",[e._v("TODO")]),e._v(" "),t("h3",{attrs:{id:"older-versions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#older-versions"}},[e._v("#")]),e._v(" Older versions")]),e._v(" "),t("p",[e._v("In PROIEL Annotator 1.x importing and exporting texts was done using "),t("code",[e._v("rake")]),e._v(" tasks:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("# Import a text\nbundle exec rake proiel:text:import FILE=new_text.xml\n\n# Import a text keeping a record of ID mapping\nbundle exec rake proiel:text:import FILE=new_text.xml ID_MAP_FILE=new_text.csv\n\n# Export a text with a specific ID\nbundle exec rake proiel:text:export ID=1\n")])])]),t("p",[e._v("The "),t("code",[e._v("rake proiel:text:export")]),e._v(" task infers the filename in the same way as "),t("code",[e._v("proiel-webapp")]),e._v(" does for PROIEL Annotator 2.x. If no "),t("code",[e._v("ID")]),e._v(" is given, all sources will be exported. Texts are by default placed in "),t("code",[e._v("public/exports")]),e._v(", but this can be overriden with the variable "),t("code",[e._v("DIRECTORY")]),e._v(" or by changing the application configuration value "),t("code",[e._v("config.export_file_path")]),e._v(". (Some earlier versions also supported exporting texts directly to other formats by setting the variable "),t("code",[e._v("FORMAT")]),e._v(". "),t("code",[e._v("proiel convert")]),e._v(" should be used even if your version supports this as "),t("code",[e._v("proiel convert")]),e._v(" is more robust.)")]),e._v(" "),t("h2",{attrs:{id:"exporting-and-importing-other-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#exporting-and-importing-other-data"}},[e._v("#")]),e._v(" Exporting and importing other data")]),e._v(" "),t("p",[e._v("Most of the maintenance tasks are designed for exporting, importing or deleting one type of object from the database, e.g. the notes that can be attached to tokens, sentences etc. We use comma-separated files for this. They must use UTF-8 encoding, have headers and should have UNIX-style line endings.")]),e._v(" "),t("p",[e._v("The following sections list the relevant commands and illustrate the expected file formats for each task.")]),e._v(" "),t("h3",{attrs:{id:"inflections"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#inflections"}},[e._v("#")]),e._v(" Inflections")]),e._v(" "),t("p",[e._v("To manipulate pre-loaded inflections, use the following commands:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Import inflections from data.csv")]),e._v("\nbin/proiel-webapp "),t("span",{pre:!0,attrs:{class:"token function"}},[e._v("import")]),e._v(" inflections data.csv\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Export inflections to data.csv")]),e._v("\nbin/proiel-webapp "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("export")]),e._v(" inflections data.csv\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Delete all inflections")]),e._v("\nbin/proiel-webapp delete inflections\n")])])]),t("p",[e._v("The file format is illustrated below")]),e._v(" "),t("div",{staticClass:"language-csv extra-class"},[t("pre",{pre:!0,attrs:{class:"language-csv"}},[t("code",[t("span",{pre:!0,attrs:{class:"token value"}},[e._v("LANGUAGE_TAG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("FORM")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("LEMMA")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("PART_OF_SPEECH_TAG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("FORM")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("MORPHOLOGY_TAG")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("lat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo#1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("V-")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("1spia----i")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("lat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("vis")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo#1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("V-")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("vis")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("2spia----i")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("lat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("vult")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo#1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("V-")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("vult")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("3spia----i")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("lat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volumus")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo#1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("V-")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volumus")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("1ppia----i")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("lat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("vultis")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo#1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("V-")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("vultis")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("2ppia----i")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("lat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volunt")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo#1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("V-")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volunt")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("3ppia----i")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("lat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo#2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("V-")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("volo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("1spia----i")]),e._v("\n")])])]),t("h3",{attrs:{id:"notes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#notes"}},[e._v("#")]),e._v(" Notes")]),e._v(" "),t("p",[e._v("To manipulate notes, use the following commands:")]),e._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Import notes from data.csv")]),e._v("\nbin/proiel-webapp "),t("span",{pre:!0,attrs:{class:"token function"}},[e._v("import")]),e._v(" notes data.csv\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Export notes to data.csv")]),e._v("\nbin/proiel-webapp "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("export")]),e._v(" notes data.csv\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Delete all notes")]),e._v("\nbin/proiel-webapp delete notes\n")])])]),t("p",[e._v("The file format is illustrated below")]),e._v(" "),t("div",{staticClass:"language-csv extra-class"},[t("pre",{pre:!0,attrs:{class:"language-csv"}},[t("code",[t("span",{pre:!0,attrs:{class:"token value"}},[e._v("ORIGINATOR_TYPE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("ORIGINATOR_ID")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("NOTABLE_TYPE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("NOTABLE_ID")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("CONTENTS")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("User")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("17")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("Sentence")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("7242")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[e._v("Direct speech within direct speech")]),e._v("\n")])])]),t("h3",{attrs:{id:"older-versions-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#older-versions-2"}},[e._v("#")]),e._v(" Older versions")]),e._v(" "),t("p",[e._v("Older versions of PROIEL Annotator used "),t("code",[e._v("rake")]),e._v(" tasks to perform these operations. It also supported some other tasks which are now performed by the "),t("code",[e._v("proiel")]),e._v(" tool. A list of all the maintenance tasks can be obtained by running the command "),t("code",[e._v("rake -T proiel")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("$ rake -T proiel\nrake proiel:dictionary:import             # Import a PROIEL dictionary.\nrake proiel:history:prune:attribute       # Prune an attribute from history.\nrake proiel:morphology:force_manual_tags  # Force manual morphological rules.\n...\n")])])]),t("p",[e._v("A number of these tasks are explained in more detail below.")]),e._v(" "),t("h2",{attrs:{id:"proiel-morphology-reassign"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-morphology-reassign"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:morphology:reassign")])]),e._v(" "),t("p",[e._v("This task is used to change all occurrences of a particular value of a\nmorphological field to another value in the "),t("code",[e._v("tokens")]),e._v(" table, i.e. to\nchange the "),t("code",[e._v("source_morphology")]),e._v(" field. For example")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("$ rake proiel:morphology:reassign FIELD=voice FROM=o TO=p\n...\n")])])]),t("p",[e._v("will replace the value "),t("code",[e._v("p")]),e._v(" with "),t("code",[e._v("o")]),e._v(" in the "),t("code",[e._v("voice")]),e._v(" field. No further\nrestrictions on the operation can be given, so the task is only useful\nfor keeping tag set and database synchronised.")]),e._v(" "),t("h2",{attrs:{id:"proiel-morphology-force-manual-tags"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-morphology-force-manual-tags"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:morphology:force_manual_tags")])]),e._v(" "),t("p",[e._v("This task will apply the morphology set out in manually crafted morpholgical rules\nto all tokens that match the criteria in the rules for given sources. This can be\nused to overwrite bad annotations once the manually crafted morphological rules are\ndeemed to be entirely correct.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("$ rake proiel:morphology:force_manual_tags SOURCES=perseus-vulgate-synth\n INFO manual-tagger: Working on source perseus-vulgate-synth...\nERROR manual-tagger: Token 251733 (sentence 12871) 'in': Tagged with closed class morphology but not found in definition.\nERROR manual-tagger: Token 251782 (sentence 12878) 'quia': Tagged with closed class morphology but not found in definition.\n")])])]),t("h2",{attrs:{id:"proiel-history-prune-attribute"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-history-prune-attribute"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:history:prune:attribute")])]),e._v(" "),t("p",[e._v("This task is used to completely remove all entries that refer to particular\nattribute from the history. This is occasionally useful when changing the database\nschema when columns are removed and the data lost by the change is of no future value.")]),e._v(" "),t("p",[e._v("Example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("$ rake proiel:history:prune:attribute MODEL=Token ATTRIBUTE=morphtag_source\nRemoving attribute Token.morphtag_source from audit 17695\nRemoving attribute Token.morphtag_source from audit 17696\nRemoving attribute Token.morphtag_source from audit 17698\nRemoving attribute Token.morphtag_source from audit 17701\nRemoving attribute Token.morphtag_source from audit 17702\nRemoving attribute Token.morphtag_source from audit 17703\n...\n")])])]),t("h2",{attrs:{id:"proiel-validate"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-validate"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:validate")])]),e._v(" "),t("p",[e._v("This task validates the entire database, first using model validations for each, then\nusing secondary constraints that have not been implemented in the models. Some of these\nare designed to be auto-correcting, e.g. orphaned lemmata are cleaned up by this task.")]),e._v(" "),t("p",[e._v("The task is intended to be run whenever the annotation scheme is modified to ensure that\nall annotation remains valid.")]),e._v(" "),t("h2",{attrs:{id:"proiel-notes-import"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-notes-import"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:notes:import")])]),e._v(" "),t("p",[e._v("This task can be used for mass-import of notes. The data file should\nbe provided in the argument "),t("code",[e._v("FILE")]),e._v(" and should be a comma-separated\nfile on the following format:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v('User,2,Sentence,12345,"a long comment here"\n')])])]),t("h2",{attrs:{id:"proiel-dependency-alignments-import"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-dependency-alignments-import"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:dependency_alignments:import")])]),e._v(" "),t("p",[e._v("This task can be used for mass-import of dependency alignment. The data file should be\na comma-separated file on the following format:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("ALIGN,12345,67890\nTERMINATE,12346,2\n")])])]),t("p",[e._v("This will align the dependency subgraph for token 67890 (in the secondary source)\nwith the dependency subgraph for token 12345 (in the primary source). It will then\nterminate the dependency subgraph for token 12346 (in the primary source) with\nrespect to the secondary source with ID 2.")]),e._v(" "),t("h2",{attrs:{id:"proiel-semantic-tags-import-and-proiel-semantic-tags-export"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-semantic-tags-import-and-proiel-semantic-tags-export"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:semantic_tags:import")]),e._v(" and "),t("code",[e._v("proiel:semantic_tags:export")])]),e._v(" "),t("p",[e._v("These tasks can be used for mass-import and -export of semantic tags. The data file is\nexpected to be a comma-separated file with the following fields:")]),e._v(" "),t("ul",[t("li",[e._v("Taggable type (string, either "),t("code",[e._v("Token")]),e._v(" or "),t("code",[e._v("Lemma")]),e._v(")")]),e._v(" "),t("li",[e._v("Taggable ID (integer)")]),e._v(" "),t("li",[e._v("Attribute tag (string)")]),e._v(" "),t("li",[e._v("Attribute value tag (string)")])]),e._v(" "),t("p",[e._v("All attributes and attribute values must already have been defined; so must any\nreferred token or lemmma.")]),e._v(" "),t("p",[e._v("Example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("$ rake proiel:semantic_tags:export FILE=tags.csv\n$ cat tags.csv\nToken,266690,animacy,-\nLemma,2256,animacy,+\n...\n$ rake proiel:semantic_tags:import FILE=tags.csv\n")])])]),t("h2",{attrs:{id:"proiel-inflections-import"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-inflections-import"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:inflections:import")])]),e._v(" "),t("p",[e._v("This task imports inflections. The data should be a comma separated\nfiles with the following fields:")]),e._v(" "),t("ul",[t("li",[e._v("Language code")]),e._v(" "),t("li",[e._v("Lemma and optional variant number separated by a hash mark (#)")]),e._v(" "),t("li",[e._v("Part of speech")]),e._v(" "),t("li",[e._v("Inflected form")]),e._v(" "),t("li",[e._v("Positional tag(s) with morphology")])]),e._v(" "),t("p",[e._v("Example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("got,and-haitan,,andhaihaist,V-2suia-----\n")])])]),t("h2",{attrs:{id:"proiel-inflections-export"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-inflections-export"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:inflections:export")])]),e._v(" "),t("p",[e._v("This task exports inflections. The format is the same as for\n"),t("code",[e._v("proiel:inflections:import")]),e._v(".")]),e._v(" "),t("h2",{attrs:{id:"proiel-bilingual-dictionary-create"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-bilingual-dictionary-create"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:bilingual_dictionary:create")])]),e._v(" "),t("p",[e._v("This task creates a dictionary of lemmas in the specified source with\ntheir presumed equivalents in the Greek original. The "),t("code",[e._v("SOURCE")]),e._v(" should be\nthe ID of the source to process. The lemmas will be referred to\nusing the database ID unless "),t("code",[e._v("FORMAT")]),e._v("="),t("code",[e._v("human")]),e._v(" is set, in which case their\nexport_form will be used instead. The dictionary is written to the\nspecified "),t("code",[e._v("FILE")]),e._v(".")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("METHOD")]),e._v(" argument specifies the statistical method used to compute\ncollocation significance. The default is "),t("code",[e._v("zvtuuf")]),e._v(", which is a log\nlikelihood measure. Other options are "),t("code",[e._v("dunning")]),e._v(", which is Dunning's\nlog likelihood measure, and "),t("code",[e._v("fisher")]),e._v(", which is Fisher's exact\ntest. The latter method requires a working installation of R and the\nrsruby gem.")]),e._v(" "),t("p",[e._v("The format of the resulting dictionary file is the following. The\nfirst line contains the number of aligned chunks (i.e. Bible verses)\nthe dictionary was based on. Next there is one line for each lemma of\nthe processed source, containing comma separated data: first, the\nlemma export form or ID, next the frequency of that lemma, and then\nthe thirty most plausible Greek original lemmas (most plausible\nfirst). For each Greek lemma, the export form or ID is given, followed\nby semi-colon separated information about that lemma and its\nco-occurrence with the given translation lemma. The following\ninformation is available:")]),e._v(" "),t("ol",[t("li",[t("code",[e._v("cr")]),e._v(" = a measure combining the rank of the translation lemma as a\ncorrespondence to the original lemma, and the original lemma as a\ncorrespondence to the translation lemma. The value is 1 divided by\nthe square root of the product of the two ranks, so if both lemma's\nare the best correspondences to each other, the value will be\n1.0. This is the value used to rank the translations.")]),e._v(" "),t("li",[t("code",[e._v("sign")]),e._v(" = the\nlog likelihood or significance value returned by the given\nstatistical test. This is used to produce the ranks that go into "),t("code",[e._v("cr")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("cooccurs")]),e._v(" = the number of times the two lemmas co-occur in the same\naligned chunk.")]),e._v(" "),t("li",[t("code",[e._v("occurs")]),e._v(" = the number of times the given Greek\nlemma occurs in the chunks that went into the creation of the\ndictionary.")])]),e._v(" "),t("p",[e._v("Thus")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("misso,freq=42,·ºÄŒªŒªŒÆŒªœâŒΩ{cr=1.0;sign=13.6667402646542;cooccurs=33;occurs=36}\n")])])]),t("p",[e._v("means that the Gothic lemma "),t("code",[e._v("misso")]),e._v(" occurs 42 times, its best Greek\nequivalent is ·ºÄŒªŒªŒÆŒªœâŒΩ, their combined rank is 1.0, the log likelihood\nvalue of the collocation is 13.66, the two lemmas co-occur 33 times,\nand ·ºÄŒªŒªŒÆŒªœâŒΩ occurs 36 times.")]),e._v(" "),t("h2",{attrs:{id:"proiel-token-alignments-set"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#proiel-token-alignments-set"}},[e._v("#")]),e._v(" "),t("code",[e._v("proiel:token_alignments:set")])]),e._v(" "),t("p",[e._v("This tasks generates token alignments, guessing at which Greek tokens\ncorrespond to which translation tokens. The task requires that a\ndictionary file (on ID format) is present in the lib directory, and\nthe name of this file must be given as the value of the "),t("code",[e._v("DICTIONARY")]),e._v("\nargument.")]),e._v(" "),t("p",[e._v("Either a "),t("code",[e._v("SOURCE")]),e._v(" or a (sequence of) "),t("code",[e._v("SOURCE_DIVISION")]),e._v("(s) to be\naligned must be specified. SOURCE_DIVISION can take single\nsource_division ID or a range of IDs (e.g. 346--349). The default\n"),t("code",[e._v("FORMAT")]),e._v(" is "),t("code",[e._v("db")]),e._v(", which writes the alignments to the database. Other\nformats are "),t("code",[e._v("csv")]),e._v(" and "),t("code",[e._v("human")]),e._v(", which write the alignments on CSV or\nhuman-readable format to standard out, or to the specified "),t("code",[e._v("FILE")]),e._v(".")])])}),[],!1,null,null,null);t.default=s.exports}}]);